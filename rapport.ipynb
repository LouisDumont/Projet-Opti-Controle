{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Opti & Contrôle - TP1**\n",
    "\n",
    "DESFORGES Guillaume & DUMONT Louis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import datas_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problème primal\n",
    "\n",
    "On s'intéresse au problème primal d'optimisation **sans contraintes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résultats théoriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({\n",
    "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montrons les équivalences des différents problèmes:\n",
    "\n",
    "On part du problème d'optimisation :\n",
    "\n",
    "\\begin{equation}\n",
    "\\underset{Aq-f = 0}{\\underset{q\\in \\mathbb{R}^{n}}{min}< q, r\\bullet q\\bullet | q|> + <p, f_r>}\n",
    "\\end{equation}\n",
    "\n",
    "La décomposition  de $A$ et $f$ sous la forme\n",
    "\n",
    "$$A = \\begin{pmatrix}\n",
    "A_r \\\\ A_d\n",
    "\\end{pmatrix}\n",
    "\\quad\n",
    "f= \\begin{pmatrix}\n",
    "f_r \\\\ f_d\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "Permet de réecrire la condition sous la forme:\n",
    "\n",
    "$$\\left\\{\n",
    "\\begin{array}{l}\n",
    "    A_d q - f_d = 0 \\\\\n",
    "    A_r q - f_r = 0\n",
    "\\end{array}\\right.$$\n",
    "\n",
    "La deuxième de ces conditions s'intègre directement dans l'énergie en remplaçant $f_r$ par $A_r q$. On obtient alors le problème équivalent:\n",
    "\n",
    "\\begin{equation}\n",
    "\\underset{A_dq-f_d = 0}{\\underset{q\\in \\mathbb{R}^{n}}{min}< q, r\\bullet q\\bullet | q|> + <p, A_rq>}\n",
    "\\end{equation}\n",
    "\n",
    "De plus, la matrice $A_d$ est de plein rang $m_d$, ce qui permet de la réecrire $A_d = (A_{d,T}\\; A_{d,C})$, où $A_{d,T}$ est inversible.\n",
    "\n",
    "En écrivant de même $q = \\begin{pmatrix} q_T \\\\ q_C \\end{pmatrix}$, la condition de $(2)$ équivaut à $$q_T = A_{d,T}^{-1} (f_d - A_{d,C}q_C )$$\n",
    "\n",
    "Une solution de $(2)$ s'écrit donc $q =q^{(0)}+B q_C$ avec \n",
    "$$q^{(0)} = \\begin{pmatrix}A^{-1}_{d,T}f_d \\\\ 0_{n-m_d}\\end{pmatrix}$$ et\n",
    "$$B = \\begin{pmatrix}-A^{-1}_{d,T}A_{d,C} \\\\ I_{n-m_d}\\end{pmatrix}$$\n",
    "\n",
    "et est solution de :\n",
    "\n",
    "\\begin{equation}\n",
    "\\underset{q_c \\in \\mathcal{R}^{n - m_d}}{min} \\frac{1}{3}<q^{(0)} + B q_c, r \\bullet(q^{(0)} + B q_c)\\bullet | q^{(0)} + B q_c| > + <p_r, A_r(q^{(0)} + B q_c)>\n",
    "\\end{equation}\n",
    "\n",
    "Réciproquement, une solution $q_C$ de $(3)$ permet de construire $q = q^{(0)} + B q_C$ solution de $(2)$ et les problèmes sont donc équivalents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule les formules du **gradient** et de la **hessienne**.\n",
    "\n",
    "Pour le gradient on a l'expression suivante :\n",
    "\n",
    "$\\nabla_{q_c}(J) = B^T (r \\bullet q \\bullet |q| + A_r^T p_r)$\n",
    "\n",
    "Et pour la Hessienne:\n",
    "\n",
    "$H_{q_c}(J) = 2B^T (r \\bullet |q| \\bullet B^T)^T $\n",
    "\n",
    "Où l'on a étendu la définition de $\\bullet$ par : $v\\bullet A$ est le produit matriciel de la matrice diagonale $diag(v_0 ,..., v_n)$ et de $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On implémente un **oracle**, c'est à dire une fonction qui puise dans les données du problème pour donner à l'algorithme d'optimisation les informations qui lui sont nécessaire : valeur du critère, vecteur gradient du critère et si demandé matrice Hessienne du critère."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.oracle import oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.random.normal(size=datas_r.n-datas_r.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test de l'oracle\")\n",
    "# test pour une valeur aléatoire\n",
    "loss, gradient, hessian = oracle(x0, compute_hessian=True)\n",
    "print(\"Critère :\", loss)\n",
    "print(\"Gradient :\", gradient)\n",
    "print(\"Hessienne :\", hessian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descentes de gradient à pas fixe ou à pas optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps, on implémente la descente de gradient à pas fixe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gradient import gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On teste la descente de gradient à pas fixe sur un problème trivial : $x^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oracle test : la fonction carré en 1 dimension\n",
    "oracle_test = lambda x: (x**2, np.array(x*2), None)\n",
    "print(\"Descente de gradient à pas fixe :\")\n",
    "result_pas_fixe = gradient(oracle_test, np.array([2]), iter_max=20, default_gradient_step=0.1, threshold=1e-16, use_wolfe=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate une convergence lente pour un problème simple. Une solution est alors d'augmenter le pas du gradient, mais ce n'est pas suffisant pour un problème plus complexe. On utilise alors l'algorithme de Wolfe pour trouver le pas optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Descente de gradient à pas optimal :\")\n",
    "result_pas_opti = gradient(oracle_test, np.array([2]), iter_max=50, threshold=1e-16, verbose=True, visual=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on pouvait s'y attendre, sur un problème convexe à une dimension la solution optimale est trouvée immédiatement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation sur le problème"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut utiliser ces algorithmes sur notre problème :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PAS FIXE :\")\n",
    "result = gradient(oracle, x0, default_gradient_step=0.0001, use_wolfe=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PAS OPTIMAL :\")\n",
    "result = gradient(oracle, x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient conjugué"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On implémente la méthode de gradient conjugué non linéaire avec l'algorithme de Polak-Ribière."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gradient_conjug_polak import gradient_polak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_polak = gradient_polak(oracle, x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthode de Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On implémente la méthode de Newton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.newton import newton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_newton = newton(oracle, x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthode quasi-Newton (BFGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On implémente la méthode dite \"quasi-Newton\" BFGS, qui utilise une approximation de l'inverse du hessien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.bfgs import bfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_bfgs = bfgs(oracle, x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problème dual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résultats théoriques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO*\n",
    "\n",
    "- Ecrire le lagrangien associé au problème sous contraintes (14) et ses conditions d’optimalité ;\n",
    "- Vérifier que ces conditions correspondent aux équations (6) et (8) de l’équilibre du réseau.\n",
    "\n",
    "- Constater que la minimisation en $q$ du lagrangien se fait de manière explicite ;\n",
    "- Donner l’expression de l’argmin $q^♯$ en fonction du multiplicateur dual $\\lambda$ et calculer les expressions de la fonction duale $\\Phi$, de son gradient et de son hessien en fonction de $\\lambda$.\n",
    "\n",
    "\n",
    "Le Lagrangien du problème $(14)$ s'écrit:\n",
    "\n",
    "$\\mathbb{L}(q, \\lambda) = \\frac{1}{3} <q, r\\bullet q\\bullet | q|> + <p_r, A_rq> + \\lambda^T(A_dq - f_d)$\n",
    "\n",
    "On cherche dans un premier temps à le minimiser (à $\\lambda$ fixé), c'est à dire à trouver les points d'annulation de son gradient. Cette condition s'écrit $r\\bullet q \\bullet |q| + A_r^T p_r + A_d^T \\lambda = 0$ (on retrouve l'équation $(8)$ de l'énoncé)\n",
    "\n",
    "L'extrémum de $\\mathbb{L}$ est donc atteint en $\\hat{q}(\\lambda) = sign(X)\\sqrt{|X|}$ où $X = -\\frac{A^{T}_r p_r + A^{T}_d \\lambda}{r}$\n",
    "\n",
    "On veut maintenant maximiser par rapport à $\\lambda$ le minimum que nous venons de calculer. Pour celà nous calculons son gradient: on note $H(\\lambda) = \\mathbb{L}(\\hat{q}(\\lambda),\\lambda)$, et on a $\\nabla H(\\lambda) = A_d\\hat{q}(\\lambda) - f_d$.\n",
    "La condition d'optimalité est donc $A_d\\hat{q}(\\lambda) - f_d = 0$, dans laquelle on retrouve l'équation $(6)$ de l'énoncé.\n",
    "\n",
    "On dispose comme on l'a vu d'une expression explicite pour $\\hat{q}(\\lambda)$ minimisant le lagrangien à $\\lambda$ fixé.\n",
    "Pour résoudre le problème de maximisation (ou son opposé problème de minimisation) du minimum du lagrangien en fonction de $\\lambda$ par les méthodes précédentes, il nous faut connaître le gradient et la hessienne de $H(\\lambda)$.\n",
    "\n",
    "Le gradient a déjà été présenté: $\\nabla H(\\lambda) = A_d\\hat{q}(\\lambda) - f_d$\n",
    "\n",
    "La Hessienne est, quant à elle, donnée par $\\nabla \\hat{q}(\\lambda) = A_d\\quad D(\\lambda) \\quad A_d^T$, où $D(\\lambda)=-\\frac{1}{r\\bullet \\sqrt{|X|}}\\bullet I_d$ où $I_d$ est la matrice identité de taille $n$.\n",
    "\n",
    "Une fois ces deux expressions établies il suffit alors d'appliquer les algorithmes d'optimisation précédents à l'opposé du problème dual (on prend l'opposé pour passer d'un problème de maximisation à un problème de minimisation).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On implémente l'oracle avec le Lagrangien :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.oracle_lagrange import oracle as oracle_dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u0 = np.random.normal(size=datas_r.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On résoud le problème dual grâce aux algorithmes précédents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PAS FIXE :\")\n",
    "result = gradient(oracle_dual, u0, default_gradient_step=0.2, use_wolfe=False, iter_max=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PAS OPTIMAL :\")\n",
    "result = gradient(oracle_dual, u0, threshold=0.01, iter_max=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_polak = gradient_polak(oracle_dual, u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_newton = newton(oracle_dual, u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_bfgs = bfgs(oracle_dual, u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
